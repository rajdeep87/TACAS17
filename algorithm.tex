\section{Abstract Conflict Driven Clause Learning}
\rmcmt{safety as satisfiability}
%
\begin{algorithm2e}[t]
\DontPrintSemicolon
\SetKwFunction{decide}{Decide}
\SetKwFunction{deduce}{deduce}
\SetKwFunction{backtrack}{backtrack}
\SetKwFunction{print}{print}
\SetKwFunction{return}{return}
\SetKwFunction{nondet}{nondet}
\SetKwFunction{run}{run}
\SetKwFunction{learn}{learn}
\SetKwFunction{continue}{continue}
\SetKwFunction{assign}{assign}
\SetKwRepeat{Do}{do}{while}
%\SetKwFunction{assume}{assume}
%\SetKwFunction{isf}{isFeasible}
\SetKwData{safe}{safe}
\SetKwData{unsafe}{unsafe}
\SetKwData{unknown}{unknown}
\SetKwData{true}{true}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKw{KwNot}{not}
\begin{small}
\Input{Program $\mathcal{P}$ with properties specified with $assert(c)$}
\Output{The status (\safe or \unsafe) and a counterexample if \unsafe}
\assign result=\deduce(P)\;
\uIf{$result == \perp$} {
  \return \safe \;
}
\uElse
{
  \uIf{is\_gamma\_complete()} {
    \return \unsafe \;
  }
}
\While{$true$} 
{
  \assign decision\_variable = decision\_heuristics($P$)\;
  %\assign decision\_container = decision\_container $\cup$ decision\_variable\; 
  \uIf{decision\_variable == NULL}
  {
    return \unknown\; 
  }
  \uElse
  {
    \assign result=\deduce(P)\;
    \uIf{result == UNKNOWN}
    {
      \uIf{is\_gamma\_complete()} {
        \return \unsafe \;
      }
      \uElse 
      {
        \continue\;
      }
    }
    \uElse
    {
      \Do{$result == \perp$} {
        \uIf{$\neg$ conflict\_analysis()} {
          return \safe \;  
        }
        \assign result=\deduce(P)\;
      }
    }
  }
}
\end{small}
\caption{Abstract Conflict Driven Clause Learning\label{Alg:acdcl}}
\end{algorithm2e}
%
\Omit {
Static program analysis based on abstract
interpretation~\cite{DBLP:conf/emsoft/Cousot07} has been widely used to
verify certain classes of properties for safety-critical systems.  In
abstract interpretation, a given program is analysed with respect to a set
of given abstract domains.  However, ACDCL is a novel program analysis 
technique that embeds an abstract domain inside the CDCL algorithm.
From the abstract interpretation point of view, ACDCL is an abstract 
interpreter that uses decision and learning to increase transformer precision. 
From the decision procedure perspective, ACDCL is a SAT solver for program 
analysis constraints and is thus a strict generalisation of propositional CDCL solvers.
Constraint propagation in ACDCL uses fixed point iteration, decisions restrict the 
range of intervals and learning generates program analysis constraints (not assumptions) 
that preserve the error reachability.  Moreover, ACDCL implicitly 
perform program and property driven trace partitioning to increase the precision
of the analysis.  
}
Algorithm~\ref{Alg:acdcl} presents an overview of the ACDCL algorithm.
Given a \rmcmt{formula (F)} and an abstract valuation $v = \top$,  
ACDCL returns {\em safe} if $F$ is unsatisfiable and P is safe. Else, 
ACDCL returns a model that satisfies $F$ and P is {\em unsafe}.  The 
procedure $deduce(P)$ is similar to BCP step in SAT solvers where 
it computes least fix-point with strongest post-condition using 
forward analysis. If the result of $deduce(P)$ 
is BOTTOM ($\perp$), the algorithm terminates with {\em safe}. Else, the 
{\em gamma completeness} check~\cite{sas01} is performed to determine if it is a 
real counterexample. If the {\em gamma completeness} check is successful, then the 
counterexample is real. Else, the algorithm enters into the while($true$)
loop and heuristically picks a meet irreducible for decision. For example, assuming 
interval domain, decisions restrict the range of intervals for variables, so the analysis jumps under a 
greatest fixed-point. Note that the widening operation in abstract interpretation 
jumps above a least fixed-point, so decisions can be viewed as 
dual widening. The procedure $deduce(P)$ is called next to deduce new facts for 
current decision. The algorithm terminates with {\em unsafe} if the result of $deduce(P)$ 
is {\em gamma complete}. Else, the algorithm enters in to $conflict\_analysis()$ phase to learn 
the reason for {\em conflict}. There can be multiple incomparable reasons for conflict --
based on the choice of Unique Implication Point (UIP), ACDCL heuristically choose one. 
A learnt clause must include asserting cuts which guarantees
derivation of new information after backtracking. The clause learning and backtracking continues 
as long as the result of deduction is BOTTOM ($\perp$) or the 
analysis backtracks to decision level 0. If no further backtrack is possible, then the 
algorithm terminates with {\em safe}. Else, the algorithm makes a new decision and 
the above process is repeated until a real counterexample is obtained or the algorithm 
backtracks to decision level 0 after a conflict in which case it returns {\em safe}. 
Currently, ACDCL handles loops in the program by unrolling the bounded loops. 
However, we are developing a new technique for automatic invariant generation using 
ACDCL for unbounded proofs. 
